{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logo.jpg', <http.client.HTTPMessage at 0x7fbf94091c70>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('http://www.pythonscraping.com')\n",
    "bs = BeautifulSoup(res.text, 'html.parser')\n",
    "imageLocation = bs.find('a',{'id':'logo'}).find('img')['src']\n",
    "urlretrieve(imageLocation, 'logo.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://pythonscraping.com/misc/jquery.js?v=1.4.4\n",
      "http://pythonscraping.com/misc/jquery.once.js?v=1.2\n",
      "http://pythonscraping.com/misc/drupal.js?q4na2g\n",
      "http://pythonscraping.com/sites/all/themes/skeletontheme/js/jquery.mobilemenu.js?q4na2g\n",
      "http://pythonscraping.com/sites/all/modules/google_analytics/googleanalytics.js?q4na2g\n",
      "http://pythonscraping.com/sites/default/files/lrg_0.jpg\n",
      "http://pythonscraping.com/https://covers.oreillystatic.com/images/0636920078067/lrg.jpg\n",
      "http://pythonscraping.com/img/lrg%20(1).jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('downloaded/img/lrg%20(1).jpg', <http.client.HTTPMessage at 0x7fd0850ff670>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "downloadDirectory = 'downloaded'\n",
    "baseUrl = 'http://pythonscraping.com'\n",
    "\n",
    "def getAbsoluteURL(baseUrl, source):\n",
    "    if source.startswith('http://www.'):\n",
    "        url = 'http://{}'.format(source[11:])\n",
    "    elif source.startswith('http://'):\n",
    "        url = source\n",
    "    elif source.startswith('www.'):\n",
    "        url = source[4:]\n",
    "        url = 'http://{}'.format(source)\n",
    "    else:\n",
    "        url = '{}/{}'.format(baseUrl, source)\n",
    "    \n",
    "    if baseUrl not in url:\n",
    "        return None\n",
    "    \n",
    "    return url\n",
    "\n",
    "def getDownloadPath(baseUrl, absoluteUrl, downloadDirectory):\n",
    "    path = absoluteUrl.replace('www.','')\n",
    "    path = path.replace(baseUrl, '')\n",
    "    path = downloadDirectory + path\n",
    "    directory = os.path.dirname(path)\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    return path\n",
    "    \n",
    "res = requests.get('http://www.pythonscraping.com')\n",
    "bs = BeautifulSoup(res.text, 'html.parser')\n",
    "downloadList = bs.find_all(src=True)\n",
    "\n",
    "for download in downloadList:\n",
    "    #print(download['src'])\n",
    "    fileUrl = getAbsoluteURL(baseUrl,download['src'])\n",
    "    if fileUrl is not None:\n",
    "        print(fileUrl)\n",
    "    \n",
    "urlretrieve(fileUrl, getDownloadPath(baseUrl, fileUrl, downloadDirectory))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "csvFile = open('test.csv', 'w+')\n",
    "try:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(('number', 'number plus 2', 'number times 2'))\n",
    "    for i in range(10):\n",
    "        writer.writerow((i, i+2, i*2))\n",
    "finally:\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://en.wikipedia.org/wiki/Comparison_of_text_editors')\n",
    "bs = BeautifulSoup(html, 'html.parser')\n",
    "table = bs.findAll('table', {'class':'wikitable'})[0]\n",
    "rows = table.findAll('tr')\n",
    "\n",
    "csvFile = open('editors.csv','wt+')\n",
    "writer = csv.writer(csvFile)\n",
    "try:\n",
    "    for row in rows:\n",
    "        csvRow = []\n",
    "        for cell in row.findAll(['td', 'th']):\n",
    "            csvRow.append(cell.get_text().strip())\n",
    "        writer.writerow(csvRow)\n",
    "finally:\n",
    "    csvFile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n",
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get(\"http://www.pythonscraping.com\")\n",
    "bs = BeautifulSoup(res.text, 'html.parser')\n",
    "downloadList = bs.find_all(src=True)\n",
    "print(downloadList.__class__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<script src=\"http://www.pythonscraping.com/misc/jquery.js?v=1.4.4\" type=\"text/javascript\"></script>\n",
      "<script src=\"http://www.pythonscraping.com/misc/jquery.once.js?v=1.2\" type=\"text/javascript\"></script>\n",
      "<script src=\"http://www.pythonscraping.com/misc/drupal.js?q4na2g\" type=\"text/javascript\"></script>\n",
      "<script src=\"http://www.pythonscraping.com/sites/all/themes/skeletontheme/js/jquery.mobilemenu.js?q4na2g\" type=\"text/javascript\"></script>\n",
      "<script src=\"http://www.pythonscraping.com/sites/all/modules/google_analytics/googleanalytics.js?q4na2g\" type=\"text/javascript\"></script>\n",
      "<img alt=\"Home\" src=\"http://www.pythonscraping.com/sites/default/files/lrg_0.jpg\"/>\n",
      "<img src=\"https://covers.oreillystatic.com/images/0636920078067/lrg.jpg\" style=\"max-width:200px;\"/>\n",
      "<img alt=\"\" src=\"http://pythonscraping.com/img/lrg%20(1).jpg\" style=\"height:394px; width:300px\"/>\n"
     ]
    }
   ],
   "source": [
    "for download in downloadList:\n",
    "    print(download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://pythonscraping.com/misc/jquery.js?v=1.4.4\n",
      "http://pythonscraping.com/misc/jquery.once.js?v=1.2\n",
      "http://pythonscraping.com/misc/drupal.js?q4na2g\n",
      "http://pythonscraping.com/sites/all/themes/skeletontheme/js/jquery.mobilemenu.js?q4na2g\n",
      "http://pythonscraping.com/sites/all/modules/google_analytics/googleanalytics.js?q4na2g\n",
      "http://pythonscraping.com/sites/default/files/lrg_0.jpg\n",
      "http://pythonscraping.com/https://covers.oreillystatic.com/images/0636920078067/lrg.jpg\n",
      "http://pythonscraping.com/img/lrg%20(1).jpg\n"
     ]
    }
   ],
   "source": [
    "baseUrl = 'http://pythonscraping.com'\n",
    "\n",
    "def getAbsoluteURL(baseUrl, source):\n",
    "    if source.startswith('http://www'):\n",
    "        url = 'http://{}'.format(source[11:])\n",
    "    elif source.startswith('http://'):\n",
    "        url = source\n",
    "    elif source.startswith('www.'):\n",
    "        url = source[4:]\n",
    "        url = 'http://{}'.format(source)\n",
    "    else:\n",
    "        url = '{}/{}'.format(baseUrl, source)\n",
    "    \n",
    "    if baseUrl not in url:\n",
    "        return None\n",
    "    \n",
    "    return url\n",
    "        \n",
    "for download in downloadList:\n",
    "    fileUrl = getAbsoluteURL(baseUrl, download['src'])\n",
    "    print(fileUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

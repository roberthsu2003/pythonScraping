import json

def convert_ipynb_comments_to_traditional(filepath):
    with open(filepath, 'r', encoding='utf-8') as f:
        notebook = json.load(f)

    for cell in notebook['cells']:
        if 'source' in cell and isinstance(cell['source'], list):
            new_source = []
            for line in cell['source']:
                # 替換常見的簡體中文詞彙為繁體中文
                line = line.replace('安装', '安裝')
                line = line.replace('设置', '設定')
                line = line.replace('导入', '導入')
                line = line.replace('异步', '非同步')
                line = line.replace('编程', '編程')
                line = line.replace('标准库', '標準庫')
                line = line.replace('嵌套', '巢狀')
                line = line.replace('事件循环', '事件循環')
                line = line.replace('支持库', '支援庫')
                line = line.replace('允许', '允許')
                line = line.replace('操作', '操作')
                line = line.replace('创建', '建立')
                line = line.replace('目录', '目錄')
                line = line.replace('生成', '產生')
                line = line.replace('带长度', '帶長度')
                line = line.replace('文件名', '檔案名稱')
                line = line.replace('完整路径', '完整路徑')
                line = line.replace('已保存到', '已儲存到')
                line = line.replace('基础形态', '基礎形態')
                line = line.replace('异步抓取网页内容', '非同步抓取網頁內容')
                line = line.replace('创建爬虫对象，自动管理资源(确保爬虫使用完后会自动关闭，释放资源)', '建立爬蟲物件，自動管理資源(確保爬蟲使用完後會自動關閉，釋放資源)')
                line = line.replace('访问指定网址并等待响应(await 关键字表示等待这个操作完成后再继续执行下面的代码)', '存取指定網址並等待回應(await 關鍵字表示等待這個操作完成後再繼續執行下面的程式碼)')
                line = line.replace('打印抓取结果', '列印抓取結果')
                line = line.replace('保存到.md文件', '儲存到.md檔案')
                line = line.replace('启动异步程序', '啟動非同步程式')
                line = line.replace('进阶形态', '進階形態')
                line = line.replace('浏览器配置', '瀏覽器配置')
                line = line.replace('控制浏览器本身的行为和启动方式', '控制瀏覽器本身的行為和啟動方式')
                line = line.replace('是否以无头模式运行, 还是显示完整界面', '是否以無頭模式執行，還是顯示完整介面')
                line = line.replace('设置用户代理来模拟不同浏览器', '設定使用者代理來模擬不同瀏覽器')
                line = line.replace('配置代理服务器等浏览器级别的设置', '配置代理伺服器等瀏覽器層級的設定')
                line = line.replace('禁用图片加载，只抓取文本内容', '禁用圖片載入，只抓取文字內容')
                line = line.replace('异步主函数，执行网页爬取任务', '非同步主函數，執行網頁爬取任務')
                line = line.replace('异步网页爬虫', '非同步網頁爬蟲')
                line = line.replace('浏览器配置', '瀏覽器配置')
                line = line.replace('爬虫运行配置', '爬蟲運行配置')
                line = line.replace('缓存模式控制', '快取模式控制')
                line = line.replace('配置浏览器参数', '配置瀏覽器參數')
                line = line.replace('无头模式，不显示浏览器窗口', '無頭模式，不顯示瀏覽器視窗')
                line = line.replace('窗口宽度', '視窗寬度')
                line = line.replace('窗口高度', '視窗高度')
                line = line.replace('浏览器标识', '瀏覽器識別')
                line = line.replace('禁用图片加载，可能会加速仅文本的爬取', '禁用圖片載入，可能會加速僅文字的爬取')
                line = line.replace('创建异步网页爬虫，自动管理资源', '建立非同步網頁爬蟲，自動管理資源')
                line = line.replace('执行网页爬取', '執行網頁爬取')
                line = line.replace('目标网址', '目標網址')
                line = line.replace('显示爬取结果', '顯示爬取結果')
                line = line.replace('内容长度', '內容長度')
                line = line.replace('前300字符预览', '前300字元預覽')
                line = line.replace('启动异步程序', '啟動非同步程式')
                line = line.replace('控制每次具体爬取任务的执行方式', '控制每次具體爬取任務的執行方式')
                line = line.replace('过滤掉过短的内容，比如导航菜单、按钮文字、简短标签', '過濾掉過短的內容，例如導覽選單、按鈕文字、簡短標籤')
                line = line.replace('自定义抓取内容，需要定义json的schema', '自訂抓取內容，需要定義json的schema')
                line = line.replace('缓存策略, 是否使用缓存', '快取策略，是否使用快取')
                line = line.replace('模拟用户点击[Load More]等按钮', '模擬使用者點擊[Load More]等按鈕')
                line = line.replace('在页面完全加载后自动截取网页截图', '在頁面完全載入後自動截取網頁截圖')
                line = line.replace('将整个网页转换为PDF文档', '將整個網頁轉換為PDF文件')
                line = line.replace('重要', '重要')
                line = line.replace('默认DefaultMarkdownGenerator()', '預設DefaultMarkdownGenerator()')
                line = line.replace('禁用缓存，获取最新内容', '禁用快取，取得最新內容')
                line = line.replace('运行配置', '執行配置')
                line = line.replace('核心功能，从网页生成干净、结构化的Markdown', '核心功能，從網頁產生乾淨、結構化的Markdown')
                line = line.replace('默认且唯一', '預設且唯一')
                line = line.replace('参数1', '參數1')
                line = line.replace('关键词过滤器', '關鍵詞過濾器')
                line = line.replace('内容精简过滤器', '內容精簡過濾器')
                line = line.replace('丢弃少于N个单词的块，因为它们可能太短或无用(不建议)', '丟棄少於N個單詞的區塊，因為它們可能太短或無用(不建議)')
                line = line.replace('固定阈值', '固定閾值')
                line = line.replace('初始阈值', '初始閾值')
                line = line.replace('固定', '固定')
                line = line.replace('变动', '變動')
                line = line.replace('创建爬虫并执行', '建立爬蟲並執行')
                line = line.replace('保存原始内容', '儲存原始內容')
                line = line.replace('保存过滤后内容', '儲存過濾後內容')
                line = line.replace('参数2', '參數2')
                line = line.replace('是否在最终markdown中移除所有超链接', '是否在最終markdown中移除所有超連結')
                line = line.replace('移除所有 [[image]]() 图片引用', '移除所有 [[image]]() 圖片引用')
                line = line.replace('将HTML实体转换为文本（默认通常为 True）', '將HTML實體轉換為文字（預設通常為 True）')
                line = line.replace('在N个字符处换行。0 或 None 表示不换行', '在N個字元處換行。0 或 None 表示不換行')
                line = line.replace('如果为 True，忽略 #localAnchors 或引用同一页面的内部链接', '如果為 True，忽略 #localAnchors 或引用同一頁面的內部連結')
                line = line.replace('尝试以更易读的方式处理 <sup> / <sub> 标签', '嘗試以更易讀的方式處理 <sup> / <sub> 標籤')
                new_source.append(line)
            cell['source'] = new_source

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, indent=2, ensure_ascii=False)

if __name__ == "__main__":
    file_path = 'crawl4AI/Crawl4AI極簡教程(核心版).ipynb'
    convert_ipynb_comments_to_traditional(file_path)

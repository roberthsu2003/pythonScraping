{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立第一個網頁爬蟲\n",
    "### 網頁爬蟲的基本動作\n",
    "\n",
    "1. 下載網頁\n",
    "2. 取出所需的資料\n",
    "3. 儲存資料\n",
    "4. 移至下一頁面，重覆上面3個動作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載整網頁內容\n",
    "- 使用urllib package 內的 request module 內的 urlopen()這個function\n",
    "- urlopen()可以透過internet來讀取資料(html檔案,影像檔或其他任何檔案)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "這個package可以幫助我們利用python物件，有效的取得HTML架構內的資料。\n",
    "\n",
    "### 安裝 BeautifulSoup\n",
    "\n",
    "```\n",
    "$ pip install beautifulsoup4\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試是否安裝成功,如果沒有發生錯誤,代表安裝成功\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用BeautifulSoup\n",
    "\n",
    "取出page1.html內的第一個h1元素\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n",
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser') #HTML content is then transformed into a BeautifulSoup object\n",
    "print(bs.h1)\n",
    "print(bs.html.body.h1)\n",
    "print(bs.html.h1)\n",
    "print(bs.body.h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: Not Found\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)    \n",
    "    #處理錯誤\n",
    "else:\n",
    "    print(\"沒有錯誤\")\n",
    "    #沒有發生錯誤\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒有發現伺服器主機\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen \n",
    "from urllib.error import HTTPError \n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen('https://pythonscrapingthisurldoesnotexist.com')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print(\"沒有發現伺服器主機\")\n",
    "else:\n",
    "    print(\"沒有發生錯誤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標籤沒有發現\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "\n",
    "try:\n",
    "    badContent = bs.header.h1\n",
    "except AttributeError as e:\n",
    "    print('標籤沒有發現')\n",
    "else:\n",
    "    if badContent == None:\n",
    "        print('標籤沒有發現')\n",
    "    else:\n",
    "        print('找到標籤')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen \n",
    "from urllib.error import HTTPError \n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getTitle(url):\n",
    "    try:\n",
    "        html = urlopen(url)\n",
    "    except HTTPError as e:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "    except AttributeError as e:\n",
    "        return None\n",
    "    \n",
    "    return title"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

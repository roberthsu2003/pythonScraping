{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b9d732aa",
      "metadata": {
        "id": "b9d732aa"
      },
      "source": [
        "# Chapter 0 - 安裝與設定"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33885186",
      "metadata": {
        "id": "33885186"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c5d25af0",
      "metadata": {
        "id": "c5d25af0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U crawl4ai\n",
        "!pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e8342717",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8342717",
        "outputId": "0dd70305-01b1-4490-ccf4-7af941c05a27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6.3\n"
          ]
        }
      ],
      "source": [
        "# Check crawl4ai version\n",
        "import crawl4ai\n",
        "print(crawl4ai.__version__.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfd6121",
      "metadata": {
        "id": "4bfd6121"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f149e07f",
      "metadata": {
        "id": "f149e07f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!crawl4ai-setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f29d68c",
      "metadata": {
        "id": "7f29d68c"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a0aa2366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0aa2366",
        "outputId": "eed9a0e6-367f-47ee-99d1-6c3c54b9c5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "zsh:1: command not found: crawl4ai-doctor\n"
          ]
        }
      ],
      "source": [
        "!crawl4ai-doctor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d48b4490",
      "metadata": {
        "id": "d48b4490"
      },
      "outputs": [],
      "source": [
        "import asyncio # 導入Python的非同步程式設計標準庫\n",
        "import nest_asyncio # 導入巢狀非同步事件迴圈支援庫\n",
        "nest_asyncio.apply() # 允許在Jupyter中使用非同步操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f3605cd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "f3605cd4",
        "outputId": "bbaca3bd-e508-4f96-a52b-33bf5d867d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Example Domain\n"
          ]
        }
      ],
      "source": [
        "from playwright.async_api import async_playwright\n",
        "\n",
        "async def test_browser():\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless = True)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto('https://example.com')\n",
        "        print(f'Title: {await page.title()}')\n",
        "        await browser.close()\n",
        "\n",
        "asyncio.run(test_browser())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a030c8e0",
      "metadata": {
        "id": "a030c8e0"
      },
      "source": [
        "## *Markdown Output Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7a9c90",
      "metadata": {
        "id": "3b7a9c90"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OUTPUT_PATH = 'outputs/markdown/'\n",
        "\n",
        "def output_md(base_filename, md_str):\n",
        "    # 建立輸出目錄\n",
        "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "    # 產生帶長度的檔案名稱\n",
        "    length = len(md_str)\n",
        "    name, ext = os.path.splitext(base_filename)\n",
        "    filename = f\"{name}({length}){ext}\"\n",
        "\n",
        "    # 完整路徑\n",
        "    full_path = os.path.join(OUTPUT_PATH, filename)\n",
        "\n",
        "    with open(full_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(md_str)\n",
        "\n",
        "    print(f\"已儲存到: {full_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d066ce",
      "metadata": {
        "id": "c7d066ce"
      },
      "source": [
        "# Chapter 1 - 基礎形態"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101673bf",
      "metadata": {
        "id": "101673bf"
      },
      "source": [
        "## 1.1 - Basic Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7fb95a4a",
      "metadata": {
        "id": "7fb95a4a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.anthropic.com/news/agent-capabilities-api</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">49s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://www.anthropic.com/news/agent-capabilities-api\u001b[0m\u001b[32m                                                |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m49s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.anthropic.com/news/agent-capabilities-api</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">02s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://www.anthropic.com/news/agent-capabilities-api\u001b[0m\u001b[32m                                                |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m02s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.anthropic.com/news/agent-capabilities-api</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">52s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://www.anthropic.com/news/agent-capabilities-api\u001b[0m\u001b[32m                                                |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m52s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Markdown length: 11049\n",
            "[Skip to main content](https://www.anthropic.com/news/agent-capabilities-api#main-content)[Skip to footer](https://www.anthropic.com/news/agent-capabilities-api#footer)\n",
            "[](https://www.anthropic.com/)\n",
            "  * Claude\n",
            "  * API\n",
            "  * Solutions\n",
            "  * Research\n",
            "  * Commitments\n",
            "  * Learn\n",
            "[News](https://www.anthropic\n",
            "已儲存到: outputs/markdown/1_1_Basic(11049).md\n"
          ]
        }
      ],
      "source": [
        "import asyncio  # 非同步程式設計庫\n",
        "from crawl4ai import AsyncWebCrawler  # 網頁抓取工具\n",
        "\n",
        "# 非同步抓取網頁內容\n",
        "async def main(output_filename):\n",
        "    # 建立爬蟲物件，自動管理資源(確保爬蟲使用完後會自動關閉，釋放資源)\n",
        "    async with AsyncWebCrawler() as crawler:\n",
        "        # 存取指定網址並等待回應(await 關鍵字表示等待這個操作完成後再繼續執行下面的程式碼)\n",
        "        result = await crawler.arun(\"https://www.anthropic.com/news/agent-capabilities-api\")\n",
        "\n",
        "        # 列印抓取結果\n",
        "        print(\"Markdown length:\", len(result.markdown))\n",
        "        print(result.markdown[:300])\n",
        "\n",
        "        # 儲存到.md檔案\n",
        "        output_md(output_filename, result.markdown)\n",
        "\n",
        "# 啟動非同步程式\n",
        "asyncio.run(main('1_1_Basic.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ca0c1b",
      "metadata": {
        "id": "95ca0c1b"
      },
      "source": [
        "# Chapter 2 - 進階形態"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805bf7ea",
      "metadata": {
        "id": "805bf7ea"
      },
      "source": [
        "## 2.1 - Setting with BrowerConfig（瀏覽器配置）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdee382",
      "metadata": {
        "id": "dbdee382"
      },
      "source": [
        "BrowserConfig - 控制瀏覽器本身的行為和啟動方式\n",
        "- headless: 是否以無頭模式運行, 還是顯示完整介面\n",
        "- user_agent: 設定使用者代理來模擬不同瀏覽器\n",
        "- proxy_config: 配置代理伺服器等瀏覽器級別的設定\n",
        "- text_mode: 禁用圖片載入，只抓取文本內容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244e2ec3",
      "metadata": {
        "id": "244e2ec3"
      },
      "outputs": [],
      "source": [
        "import asyncio  # 非同步程式設計庫\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig\n",
        "# AsyncWebCrawler: 非同步網頁爬蟲\n",
        "# BrowserConfig: 瀏覽器配置\n",
        "# CrawlerRunConfig: 爬蟲運行配置\n",
        "# CacheMode: 快取模式控制\n",
        "\n",
        "# 非同步主函數，執行網頁爬取任務\n",
        "async def main(output_filename):\n",
        "   # 配置瀏覽器參數\n",
        "   browser_config = BrowserConfig(\n",
        "       headless = True,  # 無頭模式，不顯示瀏覽器視窗\n",
        "       viewport_width = 1280,   # 視窗寬度\n",
        "       viewport_height = 720,   # 視窗高度\n",
        "       user_agent = 'Chrome/114.0.0.0',  # 瀏覽器標識\n",
        "       text_mode = True, #禁用圖片載入，可能會加速僅文本的爬取\n",
        "   )\n",
        "\n",
        "   # 建立非同步網頁爬蟲，自動管理資源\n",
        "   async with AsyncWebCrawler(config = browser_config) as crawler:\n",
        "       # 執行網頁爬取\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目標網址\n",
        "        )\n",
        "\n",
        "        # 顯示爬取結果\n",
        "        print(\"Markdown length:\", len(result.markdown))  # 內容長度\n",
        "        print(result.markdown[:300])  # 前300字元預覽\n",
        "\n",
        "        output_md(output_filename, result.markdown)\n",
        "\n",
        "# 啟動非同步程式\n",
        "asyncio.run(main('2_1_BrowserConfig.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ee5406",
      "metadata": {
        "id": "b7ee5406"
      },
      "source": [
        "## 2.2.0 - Setting with CrawlerRunConfig (爬蟲運行配置)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3bc82f6",
      "metadata": {
        "id": "c3bc82f6"
      },
      "source": [
        "CrawlerRunConfig - 控制每次具體爬取任務的執行方式\n",
        "- word_count_threshold: 過濾掉過短的內容，比如導覽選單、按鈕文字、簡短標籤\n",
        "- extraction_strategy: 自訂抓取內容，需要定義json的schema\n",
        "- cache_mode: 快取策略, 是否使用快取\n",
        "- js_code: 模擬使用者點擊[Load More]等按鈕\n",
        "- screenshot: 在頁面完全載入後自動截取網頁截圖\n",
        "- pdf: 將整個網頁轉換為PDF文件\n",
        "- [重要] markdown_generator: 預設DefaultMarkdownGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b62aa07",
      "metadata": {
        "id": "3b62aa07"
      },
      "outputs": [],
      "source": [
        "import asyncio  # 非同步程式設計庫\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n",
        "# AsyncWebCrawler: 非同步網頁爬蟲\n",
        "# BrowserConfig: 瀏覽器配置\n",
        "# CrawlerRunConfig: 爬蟲運行配置\n",
        "# CacheMode: 快取模式控制\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "# 非同步主函數，執行網頁爬取任務\n",
        "async def main(output_filename):\n",
        "   # 配置瀏覽器參數\n",
        "   browser_config = BrowserConfig(\n",
        "       headless = True,  # 無頭模式，不顯示瀏覽器視窗\n",
        "       viewport_width = 1280,   # 視窗寬度\n",
        "       viewport_height = 720,   # 視窗高度\n",
        "       user_agent = 'Chrome/114.0.0.0',  # 瀏覽器標識\n",
        "       text_mode = True, #禁用圖片載入，可能會加速僅文本的爬取\n",
        "   )\n",
        "\n",
        "   # 配置爬蟲運行參數\n",
        "   run_config = CrawlerRunConfig(\n",
        "       cache_mode = CacheMode.DISABLED,  # 禁用快取，獲取最新內容\n",
        "       markdown_generator = DefaultMarkdownGenerator(),\n",
        "   )\n",
        "\n",
        "   # 建立非同步網頁爬蟲，自動管理資源\n",
        "   async with AsyncWebCrawler(config = browser_config) as crawler:\n",
        "       # 執行網頁爬取\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目標網址\n",
        "            config = run_config,  # 運行配置\n",
        "        )\n",
        "\n",
        "        # 顯示爬取結果\n",
        "        print(\"Markdown length:\", len(result.markdown))  # 內容長度\n",
        "        print(result.markdown[:300])  # 前300字元預覽\n",
        "\n",
        "        output_md(output_filename, result.markdown)\n",
        "\n",
        "# 啟動非同步程式\n",
        "asyncio.run(main('2_2_0_RunConfig.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e96216",
      "metadata": {
        "id": "18e96216"
      },
      "source": [
        "### 2.2.1 + Content Filter: PruningContentFilter例"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e143b8b",
      "metadata": {
        "id": "6e143b8b"
      },
      "source": [
        "- **markdown_generator**: 核心功能，從網頁產生乾淨、結構化的Markdown\n",
        "    - DefaultMarkdownGenerator(預設且唯一)\n",
        "        - 參數1: Content Filters\n",
        "            - BM25ContentFilter  關鍵詞過濾器\n",
        "            - PruningContentFilter 內容精簡過濾器\n",
        "            - LLMContentFilter AI過濾器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e7e438",
      "metadata": {
        "id": "f0e7e438"
      },
      "outputs": [],
      "source": [
        "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n",
        "from crawl4ai.content_filter_strategy import PruningContentFilter\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "async def main(output_filename):\n",
        "    # 瀏覽器配置\n",
        "    browser_config = BrowserConfig(headless = True, # 無頭模式\n",
        "                                viewport_width = 1280,  # 視窗寬度\n",
        "                                viewport_height = 720,  # 視窗高度\n",
        "                                user_agent = 'Chrome/114.0.0.0', # 瀏覽器標識\n",
        "                                text_mode = True,\n",
        "                                 )\n",
        "\n",
        "    # 爬蟲運行配置\n",
        "    run_config = CrawlerRunConfig(\n",
        "    cache_mode = CacheMode.DISABLED,  # 禁用快取\n",
        "    markdown_generator = DefaultMarkdownGenerator(\n",
        "        content_filter = PruningContentFilter(\n",
        "            # min_word_threshold = 10, # 丟棄少於N個單詞的塊，因為它們可能太短或無用(不建議)\n",
        "            threshold = 0.76,  # fixded: 固定閾值 / dynamic: 初始閾值\n",
        "            threshold_type = \"fixed\", # 固定\n",
        "            # threshold_type = \"dynamic\", # 變動\n",
        "        )),\n",
        "    )\n",
        "\n",
        "    # 建立爬蟲並執行\n",
        "    async with AsyncWebCrawler(config = browser_config) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目標網址\n",
        "            config = run_config,  # 運行配置\n",
        "        )\n",
        "\n",
        "        # 儲存原始內容\n",
        "        print(\"Raw Markdown length:\", len(result.markdown.raw_markdown))\n",
        "        output_md(output_filename.replace('.md', '_raw.md'), result.markdown.raw_markdown)\n",
        "\n",
        "        # 儲存過濾後內容\n",
        "        print(\"Fit Markdown length:\", len(result.markdown.fit_markdown))\n",
        "        output_md(output_filename.replace('.md', '_fit.md'), result.markdown.fit_markdown)\n",
        "\n",
        "asyncio.run(main('2_2_1_RunConfig_ContentFilterPruning.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155724a4",
      "metadata": {
        "id": "155724a4"
      },
      "source": [
        "### 2.2.2 + Options"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03792447",
      "metadata": {
        "id": "03792447"
      },
      "source": [
        "- **markdown_generator**: 核心功能，從網頁產生乾淨、結構化的Markdown\n",
        "    - DefaultMarkdownGenerator(預設且唯一)\n",
        "        - 參數1: Content Filters\n",
        "            - BM25ContentFilter  關鍵詞過濾器\n",
        "            - PruningContentFilter 內容精簡過濾器\n",
        "            - LLMContentFilter AI過濾器\n",
        "        - 參數2: Options\n",
        "            - ignore_links (bool): 是否在最終markdown中移除所有超連結\n",
        "            - ignore_images (bool): 移除所有 [[image]]() 圖片引用\n",
        "            - escape_html (bool): 將HTML實體轉換為文本（預設通常為 True）\n",
        "            - body_width (int): 在N個字元處換行。0 或 None 表示不換行\n",
        "            - skip_internal_links (bool): 如果為 True，忽略 #localAnchors 或引用同一頁面的內部連結\n",
        "            - include_sup_sub (bool): 嘗試以更易讀的方式處理 <sup> / <sub> 標籤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789140de",
      "metadata": {
        "id": "789140de"
      },
      "outputs": [],
      "source": [
        "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n",
        "from crawl4ai.content_filter_strategy import PruningContentFilter\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "async def main(output_filename):\n",
        "    # 瀏覽器配置\n",
        "    browser_config = BrowserConfig(headless = True, # 無頭模式\n",
        "                                viewport_width = 1280,  # 視窗寬度\n",
        "                                viewport_height = 720,  # 視窗高度\n",
        "                                user_agent = 'Chrome/114.0.0.0', # 瀏覽器標識\n",
        "                                text_mode = True,\n",
        "                                 )\n",
        "\n",
        "    # 爬蟲運行配置\n",
        "    run_config = CrawlerRunConfig(\n",
        "    cache_mode = CacheMode.DISABLED,  # 禁用快取\n",
        "    markdown_generator = DefaultMarkdownGenerator(\n",
        "        content_filter = PruningContentFilter(\n",
        "            # min_word_threshold = 10, # 丟棄少於N個單詞的塊，因為它們可能太短或無用(不建議)\n",
        "            threshold = 0.76,  # fixded: 固定閾值 / dynamic: 初始閾值\n",
        "            # threshold_type = \"fixed\", # 固定\n",
        "            threshold_type = \"dynamic\", # 變動\n",
        "        ),\n",
        "        options = {\n",
        "            \"ignore_links\": True,\n",
        "            \"ignore_images\": True,\n",
        "            })\n",
        "    )\n",
        "\n",
        "    # 建立爬蟲並執行\n",
        "    async with AsyncWebCrawler(config=browser_config) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目標網址\n",
        "            config = run_config,  # 運行配置\n",
        "        )\n",
        "\n",
        "        # 儲存原始內容\n",
        "        print(\"Raw Markdown length:\", len(result.markdown.raw_markdown))\n",
        "        output_md(output_filename.replace('.md', '_raw.md'), result.markdown.raw_markdown)\n",
        "\n",
        "        # 儲存過濾後內容\n",
        "        print(\"Fit Markdown length:\", len(result.markdown.fit_markdown))\n",
        "        output_md(output_filename.replace('.md', '_fit.md'), result.markdown.fit_markdown)\n",
        "\n",
        "asyncio.run(main('2_2_2_RunConfig_ContentFilterPruning_Options.md'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "chihlee1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roberthsu2003/pythonScraping/blob/master/crawl4AI/Crawl4AI%E6%A5%B5%E7%B0%A1%E6%95%99%E7%A8%8B(%E6%A0%B8%E5%BF%83%E7%89%88).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9d732aa",
      "metadata": {
        "id": "b9d732aa"
      },
      "source": [
        "# Chapter 0 - 安装与设置"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33885186",
      "metadata": {
        "id": "33885186"
      },
      "source": [
        "## Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c5d25af0",
      "metadata": {
        "id": "c5d25af0"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U crawl4ai\n",
        "!pip install nest_asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e8342717",
      "metadata": {
        "id": "e8342717",
        "outputId": "0dd70305-01b1-4490-ccf4-7af941c05a27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6.3\n"
          ]
        }
      ],
      "source": [
        "# Check crawl4ai version\n",
        "import crawl4ai\n",
        "print(crawl4ai.__version__.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bfd6121",
      "metadata": {
        "id": "4bfd6121"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f149e07f",
      "metadata": {
        "id": "f149e07f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!crawl4ai-setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f29d68c",
      "metadata": {
        "id": "7f29d68c"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a0aa2366",
      "metadata": {
        "id": "a0aa2366",
        "outputId": "eed9a0e6-367f-47ee-99d1-6c3c54b9c5df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Running Crawl4AI health check\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
            "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n",
            "\u001b[1;36m[\u001b[0m\u001b[36mTEST\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. ℹ Testing crawling capabilities\u001b[0m\u001b[36m...\u001b[0m\u001b[36m \u001b[0m\n",
            "\u001b[1;36m[\u001b[0m\u001b[36mEXPORT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m.. ℹ Exporting media \u001b[0m\u001b[1;36m(\u001b[0m\u001b[36mPDF/MHTML/screenshot\u001b[0m\u001b[1;36m)\u001b[0m\u001b[36m took \u001b[0m\u001b[1;36m4.\u001b[0m\u001b[36m60s \u001b[0m\n",
            "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                               \u001b[0m\n",
            "\u001b[32m| \u001b[0m\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m7.\u001b[0m\u001b[32m19s \u001b[0m\n",
            "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                               \u001b[0m\n",
            "\u001b[32m| \u001b[0m\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;33m0.\u001b[0m\u001b[33m26\u001b[0m\u001b[32ms \u001b[0m\n",
            "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                               \u001b[0m\n",
            "\u001b[32m| \u001b[0m\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m7.\u001b[0m\u001b[32m48s \u001b[0m\n",
            "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● ✅ Crawling test passed! \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!crawl4ai-doctor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d48b4490",
      "metadata": {
        "id": "d48b4490"
      },
      "outputs": [],
      "source": [
        "import asyncio # 导入Python的异步编程标准库\n",
        "import nest_asyncio # 导入嵌套异步事件循环支持库\n",
        "nest_asyncio.apply() # 允许在Jupyter中使用异步操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f3605cd4",
      "metadata": {
        "id": "f3605cd4",
        "outputId": "bbaca3bd-e508-4f96-a52b-33bf5d867d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TargetClosedError",
          "evalue": "BrowserType.launch: Target page, context or browser has been closed\nBrowser logs:\n\n╔════════════════════════════════════════════════════════════════════════════════════════════════╗\n║ Looks like you launched a headed browser without having a XServer running.                     ║\n║ Set either 'headless: true' or use 'xvfb-run <your-playwright-app>' before running Playwright. ║\n║                                                                                                ║\n║ <3 Playwright Team                                                                             ║\n╚════════════════════════════════════════════════════════════════════════════════════════════════╝\nCall log:\n  - <launching> /root/.cache/ms-playwright/chromium-1169/chrome-linux/chrome --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=AcceptCHFrame,AutoExpandDetailsElement,AvoidUnnecessaryBeforeUnloadCheckSync,CertificateTransparencyComponentUpdater,DeferRendererTasksAfterInput,DestroyProfileOnBrowserClose,DialMediaRouteProvider,ExtensionManifestV2Disabled,GlobalMediaControls,HttpsUpgrades,ImprovedCookieControls,LazyFrameLoading,LensOverlay,MediaRouter,PaintHolding,ThirdPartyStoragePartitioning,Translate --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --export-tagged-pdf --disable-search-engine-choice-screen --unsafely-disable-devtools-self-xss-warnings --no-sandbox --user-data-dir=/tmp/playwright_chromiumdev_profile-lIdIbQ --remote-debugging-pipe --no-startup-window\n  - <launched> pid=10002\n  - [pid=10002][err] [10002:10017:0613/065750.116926:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n  - [pid=10002][err] [10002:10002:0613/065750.121322:ERROR:ui/ozone/platform/x11/ozone_platform_x11.cc:249] Missing X server or $DISPLAY\n  - [pid=10002][err] [10002:10002:0613/065750.121355:ERROR:ui/aura/env.cc:257] The platform failed to initialize.  Exiting.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTargetClosedError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3678358593>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_browser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3678358593>\u001b[0m in \u001b[0;36mtest_browser\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_browser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0masync_playwright\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mbrowser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchromium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheadless\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://example.com'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/playwright/async_api/_generated.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, executable_path, channel, args, ignore_default_args, handle_sigint, handle_sigterm, handle_sighup, timeout, env, headless, devtools, proxy, downloads_path, slow_mo, traces_dir, chromium_sandbox, firefox_user_prefs)\u001b[0m\n\u001b[1;32m  14449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14450\u001b[0m         return mapping.from_impl(\n\u001b[0;32m> 14451\u001b[0;31m             await self._impl_obj.launch(\n\u001b[0m\u001b[1;32m  14452\u001b[0m                 \u001b[0mexecutablePath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  14453\u001b[0m                 \u001b[0mchannel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/playwright/_impl/_browser_type.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, executablePath, channel, args, ignoreDefaultArgs, handleSIGINT, handleSIGTERM, handleSIGHUP, timeout, env, headless, devtools, proxy, downloadsPath, slowMo, tracesDir, chromiumSandbox, firefoxUserPrefs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mnormalize_launch_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         browser = cast(\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mBrowser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"launch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_did_launch_browser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrowser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/playwright/_impl/_connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, method, params)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         return await self._connection.wrap_api_call(\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_internal_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/playwright/_impl/_connection.py\u001b[0m in \u001b[0;36mwrap_api_call\u001b[0;34m(self, cb, is_internal)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mrewrite_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{parsed_st['apiName']}: {error}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api_zone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTargetClosedError\u001b[0m: BrowserType.launch: Target page, context or browser has been closed\nBrowser logs:\n\n╔════════════════════════════════════════════════════════════════════════════════════════════════╗\n║ Looks like you launched a headed browser without having a XServer running.                     ║\n║ Set either 'headless: true' or use 'xvfb-run <your-playwright-app>' before running Playwright. ║\n║                                                                                                ║\n║ <3 Playwright Team                                                                             ║\n╚════════════════════════════════════════════════════════════════════════════════════════════════╝\nCall log:\n  - <launching> /root/.cache/ms-playwright/chromium-1169/chrome-linux/chrome --disable-field-trial-config --disable-background-networking --disable-background-timer-throttling --disable-backgrounding-occluded-windows --disable-back-forward-cache --disable-breakpad --disable-client-side-phishing-detection --disable-component-extensions-with-background-pages --disable-component-update --no-default-browser-check --disable-default-apps --disable-dev-shm-usage --disable-extensions --disable-features=AcceptCHFrame,AutoExpandDetailsElement,AvoidUnnecessaryBeforeUnloadCheckSync,CertificateTransparencyComponentUpdater,DeferRendererTasksAfterInput,DestroyProfileOnBrowserClose,DialMediaRouteProvider,ExtensionManifestV2Disabled,GlobalMediaControls,HttpsUpgrades,ImprovedCookieControls,LazyFrameLoading,LensOverlay,MediaRouter,PaintHolding,ThirdPartyStoragePartitioning,Translate --allow-pre-commit-input --disable-hang-monitor --disable-ipc-flooding-protection --disable-popup-blocking --disable-prompt-on-repost --disable-renderer-backgrounding --force-color-profile=srgb --metrics-recording-only --no-first-run --enable-automation --password-store=basic --use-mock-keychain --no-service-autorun --export-tagged-pdf --disable-search-engine-choice-screen --unsafely-disable-devtools-self-xss-warnings --no-sandbox --user-data-dir=/tmp/playwright_chromiumdev_profile-lIdIbQ --remote-debugging-pipe --no-startup-window\n  - <launched> pid=10002\n  - [pid=10002][err] [10002:10017:0613/065750.116926:ERROR:dbus/bus.cc:408] Failed to connect to the bus: Failed to connect to socket /run/dbus/system_bus_socket: No such file or directory\n  - [pid=10002][err] [10002:10002:0613/065750.121322:ERROR:ui/ozone/platform/x11/ozone_platform_x11.cc:249] Missing X server or $DISPLAY\n  - [pid=10002][err] [10002:10002:0613/065750.121355:ERROR:ui/aura/env.cc:257] The platform failed to initialize.  Exiting.\n"
          ]
        }
      ],
      "source": [
        "from playwright.async_api import async_playwright\n",
        "\n",
        "async def test_browser():\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless = False)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto('https://example.com')\n",
        "        print(f'Title: {await page.title()}')\n",
        "        await browser.close()\n",
        "\n",
        "asyncio.run(test_browser())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a030c8e0",
      "metadata": {
        "id": "a030c8e0"
      },
      "source": [
        "## *Markdown Output Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7a9c90",
      "metadata": {
        "id": "3b7a9c90"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "OUTPUT_PATH = '../outputs/markdown/'\n",
        "\n",
        "def output_md(base_filename, md_str):\n",
        "    # 创建输出目录\n",
        "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "    # 生成带长度的文件名\n",
        "    length = len(md_str)\n",
        "    name, ext = os.path.splitext(base_filename)\n",
        "    filename = f\"{name}({length}){ext}\"\n",
        "\n",
        "    # 完整路径\n",
        "    full_path = os.path.join(OUTPUT_PATH, filename)\n",
        "\n",
        "    with open(full_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(md_str)\n",
        "\n",
        "    print(f\"已保存到: {full_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7d066ce",
      "metadata": {
        "id": "c7d066ce"
      },
      "source": [
        "# Chapter 1 - 基础形态"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101673bf",
      "metadata": {
        "id": "101673bf"
      },
      "source": [
        "## 1.1 - Basic Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fb95a4a",
      "metadata": {
        "id": "7fb95a4a"
      },
      "outputs": [],
      "source": [
        "import asyncio  # 异步编程库\n",
        "from crawl4ai import AsyncWebCrawler  # 网页抓取工具\n",
        "\n",
        "# 异步抓取网页内容\n",
        "async def main(output_filename):\n",
        "    # 创建爬虫对象，自动管理资源(确保爬虫使用完后会自动关闭，释放资源)\n",
        "    async with AsyncWebCrawler() as crawler:\n",
        "        # 访问指定网址并等待响应(await 关键字表示等待这个操作完成后再继续执行下面的代码)\n",
        "        result = await crawler.arun(\"https://www.anthropic.com/news/agent-capabilities-api\")\n",
        "\n",
        "        # 打印抓取结果\n",
        "        print(\"Markdown length:\", len(result.markdown))\n",
        "        print(result.markdown[:300])\n",
        "\n",
        "        # 保存到.md文件\n",
        "        output_md(output_filename, result.markdown)\n",
        "\n",
        "# 启动异步程序\n",
        "asyncio.run(main('1_1_Basic.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95ca0c1b",
      "metadata": {
        "id": "95ca0c1b"
      },
      "source": [
        "# Chapter 2 - 进阶形态"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805bf7ea",
      "metadata": {
        "id": "805bf7ea"
      },
      "source": [
        "## 2.1 - Setting with BrowerConfig（浏览器配置）"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbdee382",
      "metadata": {
        "id": "dbdee382"
      },
      "source": [
        "BrowserConfig - 控制浏览器本身的行为和启动方式\n",
        "- headless: 是否以无头模式运行, 还是显示完整界面\n",
        "- user_agent: 设置用户代理来模拟不同浏览器\n",
        "- proxy_config: 配置代理服务器等浏览器级别的设置\n",
        "- text_mode: 禁用图片加载，只抓取文本内容"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "244e2ec3",
      "metadata": {
        "id": "244e2ec3"
      },
      "outputs": [],
      "source": [
        "import asyncio  # 异步编程库\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig\n",
        "# AsyncWebCrawler: 异步网页爬虫\n",
        "# BrowserConfig: 浏览器配置\n",
        "# CrawlerRunConfig: 爬虫运行配置\n",
        "# CacheMode: 缓存模式控制\n",
        "\n",
        "# 异步主函数，执行网页爬取任务\n",
        "async def main(output_filename):\n",
        "   # 配置浏览器参数\n",
        "   browser_config = BrowserConfig(\n",
        "       headless = True,  # 无头模式，不显示浏览器窗口\n",
        "       viewport_width = 1280,   # 窗口宽度\n",
        "       viewport_height = 720,   # 窗口高度\n",
        "       user_agent = 'Chrome/114.0.0.0',  # 浏览器标识\n",
        "       text_mode = True, #禁用图片加载，可能会加速仅文本的爬取\n",
        "   )\n",
        "\n",
        "   # 创建异步网页爬虫，自动管理资源\n",
        "   async with AsyncWebCrawler(config = browser_config) as crawler:\n",
        "       # 执行网页爬取\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目标网址\n",
        "        )\n",
        "\n",
        "        # 显示爬取结果\n",
        "        print(\"Markdown length:\", len(result.markdown))  # 内容长度\n",
        "        print(result.markdown[:300])  # 前300字符预览\n",
        "\n",
        "        output_md(output_filename, result.markdown)\n",
        "\n",
        "# 启动异步程序\n",
        "asyncio.run(main('2_1_BrowserConfig.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ee5406",
      "metadata": {
        "id": "b7ee5406"
      },
      "source": [
        "## 2.2.0 - Setting with CrawlerRunConfig (爬虫运行配置)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3bc82f6",
      "metadata": {
        "id": "c3bc82f6"
      },
      "source": [
        "CrawlerRunConfig - 控制每次具体爬取任务的执行方式\n",
        "- word_count_threshold: 过滤掉过短的内容，比如导航菜单、按钮文字、简短标签\n",
        "- extraction_strategy: 自定义抓取内容，需要定义json的schema\n",
        "- cache_mode: 缓存策略, 是否使用缓存\n",
        "- js_code: 模拟用户点击[Load More]等按钮\n",
        "- screenshot: 在页面完全加载后自动截取网页截图\n",
        "- pdf: 将整个网页转换为PDF文档\n",
        "- [重要] markdown_generator: 默认DefaultMarkdownGenerator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b62aa07",
      "metadata": {
        "id": "3b62aa07"
      },
      "outputs": [],
      "source": [
        "import asyncio  # 异步编程库\n",
        "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n",
        "# AsyncWebCrawler: 异步网页爬虫\n",
        "# BrowserConfig: 浏览器配置\n",
        "# CrawlerRunConfig: 爬虫运行配置\n",
        "# CacheMode: 缓存模式控制\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "# 异步主函数，执行网页爬取任务\n",
        "async def main(output_filename):\n",
        "   # 配置浏览器参数\n",
        "   browser_config = BrowserConfig(\n",
        "       headless = True,  # 无头模式，不显示浏览器窗口\n",
        "       viewport_width = 1280,   # 窗口宽度\n",
        "       viewport_height = 720,   # 窗口高度\n",
        "       user_agent = 'Chrome/114.0.0.0',  # 浏览器标识\n",
        "       text_mode = True, #禁用图片加载，可能会加速仅文本的爬取\n",
        "   )\n",
        "\n",
        "   # 配置爬虫运行参数\n",
        "   run_config = CrawlerRunConfig(\n",
        "       cache_mode = CacheMode.DISABLED,  # 禁用缓存，获取最新内容\n",
        "       markdown_generator = DefaultMarkdownGenerator(),\n",
        "   )\n",
        "\n",
        "   # 创建异步网页爬虫，自动管理资源\n",
        "   async with AsyncWebCrawler(config = browser_config) as crawler:\n",
        "       # 执行网页爬取\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目标网址\n",
        "            config = run_config,  # 运行配置\n",
        "        )\n",
        "\n",
        "        # 显示爬取结果\n",
        "        print(\"Markdown length:\", len(result.markdown))  # 内容长度\n",
        "        print(result.markdown[:300])  # 前300字符预览\n",
        "\n",
        "        output_md(output_filename, result.markdown)\n",
        "\n",
        "# 启动异步程序\n",
        "asyncio.run(main('2_2_0_RunConfig.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18e96216",
      "metadata": {
        "id": "18e96216"
      },
      "source": [
        "### 2.2.1 + Content Filter: PruningContentFilter例"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e143b8b",
      "metadata": {
        "id": "6e143b8b"
      },
      "source": [
        "- **markdown_generator**: 核心功能，从网页生成干净、结构化的Markdown\n",
        "    - DefaultMarkdownGenerator(默认且唯一)\n",
        "        - 参数1: Content Filters\n",
        "            - BM25ContentFilter  关键词过滤器\n",
        "            - PruningContentFilter 内容精简过滤器\n",
        "            - LLMContentFilter AI过滤器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e7e438",
      "metadata": {
        "id": "f0e7e438"
      },
      "outputs": [],
      "source": [
        "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n",
        "from crawl4ai.content_filter_strategy import PruningContentFilter\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "async def main(output_filename):\n",
        "    # 浏览器配置\n",
        "    browser_config = BrowserConfig(headless = True, # 无头模式\n",
        "                                viewport_width = 1280,  # 窗口宽度\n",
        "                                viewport_height = 720,  # 窗口高度\n",
        "                                user_agent = 'Chrome/114.0.0.0', # 浏览器标识\n",
        "                                text_mode = True,\n",
        "                                 )\n",
        "\n",
        "    # 爬虫运行配置\n",
        "    run_config = CrawlerRunConfig(\n",
        "    cache_mode = CacheMode.DISABLED,  # 禁用缓存\n",
        "    markdown_generator = DefaultMarkdownGenerator(\n",
        "        content_filter = PruningContentFilter(\n",
        "            # min_word_threshold = 10, # 丢弃少于N个单词的块，因为它们可能太短或无用(不建议)\n",
        "            threshold = 0.76,  # fixded: 固定阈值 / dynamic: 初始阈值\n",
        "            threshold_type = \"fixed\", # 固定\n",
        "            # threshold_type = \"dynamic\", # 变动\n",
        "        )),\n",
        "    )\n",
        "\n",
        "    # 创建爬虫并执行\n",
        "    async with AsyncWebCrawler(config = browser_config) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目标网址\n",
        "            config = run_config,  # 运行配置\n",
        "        )\n",
        "\n",
        "        # 保存原始内容\n",
        "        print(\"Raw Markdown length:\", len(result.markdown.raw_markdown))\n",
        "        output_md(output_filename.replace('.md', '_raw.md'), result.markdown.raw_markdown)\n",
        "\n",
        "        # 保存过滤后内容\n",
        "        print(\"Fit Markdown length:\", len(result.markdown.fit_markdown))\n",
        "        output_md(output_filename.replace('.md', '_fit.md'), result.markdown.fit_markdown)\n",
        "\n",
        "asyncio.run(main('2_2_1_RunConfig_ContentFilterPruning.md'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "155724a4",
      "metadata": {
        "id": "155724a4"
      },
      "source": [
        "### 2.2.2 + Options"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03792447",
      "metadata": {
        "id": "03792447"
      },
      "source": [
        "- **markdown_generator**: 核心功能，从网页生成干净、结构化的Markdown\n",
        "    - DefaultMarkdownGenerator(默认且唯一)\n",
        "        - 参数1: Content Filters\n",
        "            - BM25ContentFilter  关键词过滤器\n",
        "            - PruningContentFilter 内容精简过滤器\n",
        "            - LLMContentFilter AI过滤器\n",
        "        - 参数2: Options\n",
        "            - ignore_links (bool): 是否在最终markdown中移除所有超链接\n",
        "            - ignore_images (bool): 移除所有 [[image]]() 图片引用\n",
        "            - escape_html (bool): 将HTML实体转换为文本（默认通常为 True）\n",
        "            - body_width (int): 在N个字符处换行。0 或 None 表示不换行\n",
        "            - skip_internal_links (bool): 如果为 True，忽略 #localAnchors 或引用同一页面的内部链接\n",
        "            - include_sup_sub (bool): 尝试以更易读的方式处理 <sup> / <sub> 标签"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "789140de",
      "metadata": {
        "id": "789140de"
      },
      "outputs": [],
      "source": [
        "from crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n",
        "from crawl4ai.content_filter_strategy import PruningContentFilter\n",
        "from crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\n",
        "\n",
        "async def main(output_filename):\n",
        "    # 浏览器配置\n",
        "    browser_config = BrowserConfig(headless = True, # 无头模式\n",
        "                                viewport_width = 1280,  # 窗口宽度\n",
        "                                viewport_height = 720,  # 窗口高度\n",
        "                                user_agent = 'Chrome/114.0.0.0', # 浏览器标识\n",
        "                                text_mode = True,\n",
        "                                 )\n",
        "\n",
        "    # 爬虫运行配置\n",
        "    run_config = CrawlerRunConfig(\n",
        "    cache_mode = CacheMode.DISABLED,  # 禁用缓存\n",
        "    markdown_generator = DefaultMarkdownGenerator(\n",
        "        content_filter = PruningContentFilter(\n",
        "            # min_word_threshold = 10, # 丢弃少于N个单词的块，因为它们可能太短或无用(不建议)\n",
        "            threshold = 0.76,  # fixded: 固定阈值 / dynamic: 初始阈值\n",
        "            # threshold_type = \"fixed\", # 固定\n",
        "            threshold_type = \"dynamic\", # 变动\n",
        "        ),\n",
        "        options = {\n",
        "            \"ignore_links\": True,\n",
        "            \"ignore_images\": True,\n",
        "            })\n",
        "    )\n",
        "\n",
        "    # 创建爬虫并执行\n",
        "    async with AsyncWebCrawler(config=browser_config) as crawler:\n",
        "        result = await crawler.arun(\n",
        "            url = \"https://www.anthropic.com/news/agent-capabilities-api\",  # 目标网址\n",
        "            config = run_config,  # 运行配置\n",
        "        )\n",
        "\n",
        "        # 保存原始内容\n",
        "        print(\"Raw Markdown length:\", len(result.markdown.raw_markdown))\n",
        "        output_md(output_filename.replace('.md', '_raw.md'), result.markdown.raw_markdown)\n",
        "\n",
        "        # 保存过滤后内容\n",
        "        print(\"Fit Markdown length:\", len(result.markdown.fit_markdown))\n",
        "        output_md(output_filename.replace('.md', '_fit.md'), result.markdown.fit_markdown)\n",
        "\n",
        "asyncio.run(main('2_2_2_RunConfig_ContentFilterPruning_Options.md'))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "crawl4ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
## 使用調度程序進行高級多URL抓取(Advanced Multi-URL Crawling with Dispatchers)

- [官網說明](https://docs.crawl4ai.com/advanced/multi-url-crawling/)

## Dispatchers 在 Advanced Multi-URL Crawling 的角色

**Dispatchers（調度器）**是現代網頁爬蟲系統（如 Crawl4AI）在進行多網址（Multi-URL）爬取時的核心組件。它們負責管理多個爬取任務的**併發執行、資源分配、速率限制與記憶體控制**，確保系統能高效且穩定地處理大量網址的爬取需求

### 為什麼需要 Dispatchers？

- **併發管理**：同時處理多個網址的爬取，提升效率。
- **記憶體與資源控制**：根據系統資源自動調整同時執行的任務數，避免超載。
- **速率限制**：根據目標網站的限制，自動調整請求速率，遇到 429 或 503 等錯誤時自動退避。
- **即時監控**：可監控每個任務的狀態、記憶體用量與整體進度。
- **靈活性**：可根據需求選擇不同的調度策略（如記憶體自適應或信號量控制）[1][2][3][4]。

### 常見的 Dispatcher 類型

| 類型                     | 特點與適用情境                                      |
|--------------------------|----------------------------------------------------|
| MemoryAdaptiveDispatcher | 根據系統記憶體自動調整併發數，適合資源有限的環境      |
| SemaphoreDispatcher      | 以信號量控制最大併發數，適合需要嚴格限制同時任務數量  |

### 工作原理簡述

- **arun_many()** 是多網址爬取的主要函式，內部自動運用 dispatcher 來管理所有網址的爬取流程。
- 使用 dispatcher，可以實現：
  - 任務分批、動態調整併發數
  - 針對不同網址自動速率限制
  - 當系統資源緊張時自動暫停或減慢爬取速度
  - 任務失敗時自動重試，並記錄錯誤資訊

### 實務應用場景

- **大規模網站資料蒐集**：同時爬取成千上萬個網址，dispatcher 可確保不會因資源耗盡而崩潰。
- **API 資料同步**：需遵守 API 速率限制時，dispatcher 可自動調整請求頻率。
- **動態監控**：即時觀察爬蟲運作狀態、效能瓶頸與錯誤分佈

### 總結

**Dispatcher** 是多網址爬取的「智慧調度大腦」，能讓爬蟲在高效率與資源安全間取得最佳平衡。選擇合適的 dispatcher 並根據需求調整參數，是進行大規模網路資料蒐集的最佳實踐

---

> [!IMPORTANT]
> 注意：Crawl4AI 支援進階調度程序，用於並行或限速爬取，提供動態速率限制和記憶體使用檢查。內建的 arun_many() 函數使用這些排程器來有效率地處理並發。

## 介紹

**抓取多個 URL 時：**  

1. 基本方法：循環使用 arun()（簡單但效率較低）
2. 更好方法：使用 arun_many()，它可以有效處理多個 URL 並進行適當的並發控制
3. 最佳方法：根據您的特定需求（記憶體管理、速率限制等）自訂排程器行為


**為什麼是調度員？**

- 自適應：基於記憶體的調度程式可根據系統資源暫停或減慢速度
- 速率限制：內建速率限制，支援 429/503 反應的指數退避
- 即時監控：即時顯示正在進行的任務、記憶體使用情況和效能的儀表板
- 靈活性：可選擇記憶體自適應或基於信號量的並發

**‼️實際案例:**

- 基本方法:
	- [**使用loop的方式1**](./lesson1_爬取台灣即時股票資訊_loop方式.py)
		
		```
		爬取台灣即時股票資訊
		使用asyncio.run(main())
		使用for loop
		```
		
		- [**做用loop的方式1**](./lesson2_爬取台灣即時股票資訊_async方式.py)

			```
			爬取台灣即時股票資訊
			使用asyncio.gather()
			使用for loop的方式
			```
			
- 更好方法:

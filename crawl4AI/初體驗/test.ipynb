{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d33aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.\n"
     ]
    }
   ],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "import asyncio\n",
    "\n",
    "async def run():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto('https://example.com')\n",
    "        await page.wait_for_selector('p') #Á≠âÂæÖÂÖÉÁ¥†ËºâÂÖ•\n",
    "        content = await page.inner_text('p')\n",
    "        print(content)\n",
    "        await browser.close()\n",
    "    \n",
    "await run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b7f62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... ‚Üí Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. ‚Üí Crawl4AI \u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m3\u001b[0m\u001b[36m \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ‚Üì </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://crawl4ai.com</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                                 |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">‚úì | ‚è±: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4.</span><span style=\"color: #008000; text-decoration-color: #008000\">24s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ‚Üì \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                                                                 |\u001b[0m\n",
       "\u001b[32m‚úì\u001b[0m\u001b[32m | ‚è±: \u001b[0m\u001b[1;32m4.\u001b[0m\u001b[32m24s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ‚óÜ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://crawl4ai.com</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                                 |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">‚úì | ‚è±: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">02s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ‚óÜ \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                                                                 |\u001b[0m\n",
       "\u001b[32m‚úì\u001b[0m\u001b[32m | ‚è±: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m02s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ‚óè </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://crawl4ai.com</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                                 |</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">‚úì | ‚è±: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">4.</span><span style=\"color: #008000; text-decoration-color: #008000\">26s </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ‚óè \u001b[0m\u001b[4;32mhttps://crawl4ai.com\u001b[0m\u001b[32m                                                                                 |\u001b[0m\n",
       "\u001b[32m‚úì\u001b[0m\u001b[32m | ‚è±: \u001b[0m\u001b[1;32m4.\u001b[0m\u001b[32m26s \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Crawl4AI Documentation (v0.6.x)](https://docs.crawl4ai.com/)\n",
      "  * [ Home ](https://docs.crawl4ai.com/)\n",
      "  * [ Ask AI ](https://docs.crawl4ai.com/core/ask-ai/)\n",
      "  * [ LLM Context ](https://docs.crawl4ai.com/core/llmtxt/)\n",
      "  * [ Quick Start ](https://docs.crawl4ai.com/core/quickstart/)\n",
      "  * [ Code Examples ](https://docs.crawl4ai.com/core/examples/)\n",
      "  * [ Search ](https://docs.crawl4ai.com/)\n",
      "\n",
      "\n",
      "√ó\n",
      "  * Home\n",
      "  * [Ask AI](https://docs.crawl4ai.com/core/ask-ai/)\n",
      "  * [LLM Context](https://docs.crawl4ai.com/core/llmtxt/)\n",
      "  * [Quick Start](https://docs.crawl4ai.com/core/quickstart/)\n",
      "  * [Code Examples](https://docs.crawl4ai.com/core/examples/)\n",
      "  * Setup & Installation\n",
      "    * [Installation](https://docs.crawl4ai.com/core/installation/)\n",
      "    * [Docker Deployment](https://docs.crawl4ai.com/core/docker-deployment/)\n",
      "  * Blog & Changelog\n",
      "    * [Blog Home](https://docs.crawl4ai.com/blog/)\n",
      "    * [Changelog](https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md)\n",
      "  * Core\n",
      "    * [Command Line Interface](https://docs.crawl4ai.com/core/cli/)\n",
      "    * [Simple Crawling](https://docs.crawl4ai.com/core/simple-crawling/)\n",
      "    * [Deep Crawling](https://docs.crawl4ai.com/core/deep-crawling/)\n",
      "    * [Crawler Result](https://docs.crawl4ai.com/core/crawler-result/)\n",
      "    * [Browser, Crawler & LLM Config](https://docs.crawl4ai.com/core/browser-crawler-config/)\n",
      "    * [Markdown Generation](https://docs.crawl4ai.com/core/markdown-generation/)\n",
      "    * [Fit Markdown](https://docs.crawl4ai.com/core/fit-markdown/)\n",
      "    * [Page Interaction](https://docs.crawl4ai.com/core/page-interaction/)\n",
      "    * [Content Selection](https://docs.crawl4ai.com/core/content-selection/)\n",
      "    * [Cache Modes](https://docs.crawl4ai.com/core/cache-modes/)\n",
      "    * [Local Files & Raw HTML](https://docs.crawl4ai.com/core/local-files/)\n",
      "    * [Link & Media](https://docs.crawl4ai.com/core/link-media/)\n",
      "  * Advanced\n",
      "    * [Overview](https://docs.crawl4ai.com/advanced/advanced-features/)\n",
      "    * [File Downloading](https://docs.crawl4ai.com/advanced/file-downloading/)\n",
      "    * [Lazy Loading](https://docs.crawl4ai.com/advanced/lazy-loading/)\n",
      "    * [Hooks & Auth](https://docs.crawl4ai.com/advanced/hooks-auth/)\n",
      "    * [Proxy & Security](https://docs.crawl4ai.com/advanced/proxy-security/)\n",
      "    * [Session Management](https://docs.crawl4ai.com/advanced/session-management/)\n",
      "    * [Multi-URL Crawling](https://docs.crawl4ai.com/advanced/multi-url-crawling/)\n",
      "    * [Crawl Dispatcher](https://docs.crawl4ai.com/advanced/crawl-dispatcher/)\n",
      "    * [Identity Based Crawling](https://docs.crawl4ai.com/advanced/identity-based-crawling/)\n",
      "    * [SSL Certificate](https://docs.crawl4ai.com/advanced/ssl-certificate/)\n",
      "    * [Network & Console Capture](https://docs.crawl4ai.com/advanced/network-console-capture/)\n",
      "  * Extraction\n",
      "    * [LLM-Free Strategies](https://docs.crawl4ai.com/extraction/no-llm-strategies/)\n",
      "    * [LLM Strategies](https://docs.crawl4ai.com/extraction/llm-strategies/)\n",
      "    * [Clustering Strategies](https://docs.crawl4ai.com/extraction/clustring-strategies/)\n",
      "    * [Chunking](https://docs.crawl4ai.com/extraction/chunking/)\n",
      "  * API Reference\n",
      "    * [AsyncWebCrawler](https://docs.crawl4ai.com/api/async-webcrawler/)\n",
      "    * [arun()](https://docs.crawl4ai.com/api/arun/)\n",
      "    * [arun_many()](https://docs.crawl4ai.com/api/arun_many/)\n",
      "    * [Browser, Crawler & LLM Config](https://docs.crawl4ai.com/api/parameters/)\n",
      "    * [CrawlResult](https://docs.crawl4ai.com/api/crawl-result/)\n",
      "    * [Strategies](https://docs.crawl4ai.com/api/strategies/)\n",
      "\n",
      "\n",
      "  * [üöÄü§ñ Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper](https://docs.crawl4ai.com/#crawl4ai-open-source-llm-friendly-web-crawler-scraper)\n",
      "  * [Quick Start](https://docs.crawl4ai.com/#quick-start)\n",
      "  * [Video Tutorial](https://docs.crawl4ai.com/#video-tutorial)\n",
      "  * [What Does Crawl4AI Do?](https://docs.crawl4ai.com/#what-does-crawl4ai-do)\n",
      "  * [Documentation Structure](https://docs.crawl4ai.com/#documentation-structure)\n",
      "  * [How You Can Support](https://docs.crawl4ai.com/#how-you-can-support)\n",
      "  * [Quick Links](https://docs.crawl4ai.com/#quick-links)\n",
      "\n",
      "\n",
      "# üöÄü§ñ Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper\n",
      "[ ![unclecode%2Fcrawl4ai | Trendshift](https://trendshift.io/api/badge/repositories/11716) ](https://trendshift.io/repositories/11716)\n",
      "[ ![GitHub Stars](https://img.shields.io/github/stars/unclecode/crawl4ai?style=social) ](https://github.com/unclecode/crawl4ai/stargazers) [ ![GitHub Forks](https://img.shields.io/github/forks/unclecode/crawl4ai?style=social) ](https://github.com/unclecode/crawl4ai/network/members) [ ![PyPI version](https://badge.fury.io/py/crawl4ai.svg) ](https://badge.fury.io/py/crawl4ai)\n",
      "[ ![Python Version](https://img.shields.io/pypi/pyversions/crawl4ai) ](https://pypi.org/project/crawl4ai/) [ ![Downloads](https://static.pepy.tech/badge/crawl4ai/month) ](https://pepy.tech/project/crawl4ai) [ ![License](https://img.shields.io/github/license/unclecode/crawl4ai) ](https://github.com/unclecode/crawl4ai/blob/main/LICENSE)\n",
      "Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for large language models, AI agents, and data pipelines. Fully open source, flexible, and built for real-time performance, **Crawl4AI** empowers developers with unmatched speed, precision, and deployment ease.\n",
      "> **Note** : If you're looking for the old documentation, you can access it [here](https://old.docs.crawl4ai.com).\n",
      "## Quick Start\n",
      "Here's a quick example to show you how easy it is to use Crawl4AI with its asynchronous capabilities:\n",
      "```\n",
      "import asyncio\n",
      "from crawl4ai import AsyncWebCrawler\n",
      "async def main():\n",
      "  # Create an instance of AsyncWebCrawler\n",
      "  async with AsyncWebCrawler() as crawler:\n",
      "    # Run the crawler on a URL\n",
      "    result = await crawler.arun(url=\"https://crawl4ai.com\")\n",
      "    # Print the extracted content\n",
      "    print(result.markdown)\n",
      "# Run the async main function\n",
      "asyncio.run(main())\n",
      "Copy\n",
      "```\n",
      "\n",
      "## Video Tutorial\n",
      "## What Does Crawl4AI Do?\n",
      "Crawl4AI is a feature-rich crawler and scraper that aims to:\n",
      "1. **Generate Clean Markdown** : Perfect for RAG pipelines or direct ingestion into LLMs. 2. **Structured Extraction** : Parse repeated patterns with CSS, XPath, or LLM-based extraction. 3. **Advanced Browser Control** : Hooks, proxies, stealth modes, session re-use‚Äîfine-grained control. 4. **High Performance** : Parallel crawling, chunk-based extraction, real-time use cases. 5. **Open Source** : No forced API keys, no paywalls‚Äîeveryone can access their data. \n",
      "**Core Philosophies** : - **Democratize Data** : Free to use, transparent, and highly configurable. - **LLM Friendly** : Minimally processed, well-structured text, images, and metadata, so AI models can easily consume it.\n",
      "## Documentation Structure\n",
      "To help you get started, we‚Äôve organized our docs into clear sections:\n",
      "  * **Setup & Installation** Basic instructions to install Crawl4AI via pip or Docker. \n",
      "  * **Quick Start** A hands-on introduction showing how to do your first crawl, generate Markdown, and do a simple extraction. \n",
      "  * **Core** Deeper guides on single-page crawling, advanced browser/crawler parameters, content filtering, and caching. \n",
      "  * **Advanced** Explore link & media handling, lazy loading, hooking & authentication, proxies, session management, and more. \n",
      "  * **Extraction** Detailed references for no-LLM (CSS, XPath) vs. LLM-based strategies, chunking, and clustering approaches. \n",
      "  * **API Reference** Find the technical specifics of each class and method, including `AsyncWebCrawler`, `arun()`, and `CrawlResult`.\n",
      "\n",
      "\n",
      "Throughout these sections, you‚Äôll find code samples you can **copy-paste** into your environment. If something is missing or unclear, raise an issue or PR.\n",
      "## How You Can Support\n",
      "  * **Star & Fork**: If you find Crawl4AI helpful, star the repo on GitHub or fork it to add your own features. \n",
      "  * **File Issues** : Encounter a bug or missing feature? Let us know by filing an issue, so we can improve. \n",
      "  * **Pull Requests** : Whether it‚Äôs a small fix, a big feature, or better docs‚Äîcontributions are always welcome. \n",
      "  * **Join Discord** : Come chat about web scraping, crawling tips, or AI workflows with the community. \n",
      "  * **Spread the Word** : Mention Crawl4AI in your blog posts, talks, or on social media. \n",
      "\n",
      "\n",
      "**Our mission** : to empower everyone‚Äîstudents, researchers, entrepreneurs, data scientists‚Äîto access, parse, and shape the world‚Äôs data with speed, cost-efficiency, and creative freedom.\n",
      "## Quick Links\n",
      "  * **[GitHub Repo](https://github.com/unclecode/crawl4ai)**\n",
      "  * **[Installation Guide](https://docs.crawl4ai.com/core/installation/)**\n",
      "  * **[Quick Start](https://docs.crawl4ai.com/core/quickstart/)**\n",
      "  * **[API Reference](https://docs.crawl4ai.com/api/async-webcrawler/)**\n",
      "  * **[Changelog](https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md)**\n",
      "\n",
      "\n",
      "Thank you for joining me on this journey. Let‚Äôs keep building an **open, democratic** approach to data extraction and AI together.\n",
      "Happy Crawling! ‚Äî _Unclecode, Founder & Maintainer of Crawl4AI_\n",
      "#### On this page\n",
      "  * [Quick Start](https://docs.crawl4ai.com/#quick-start)\n",
      "  * [Video Tutorial](https://docs.crawl4ai.com/#video-tutorial)\n",
      "  * [What Does Crawl4AI Do?](https://docs.crawl4ai.com/#what-does-crawl4ai-do)\n",
      "  * [Documentation Structure](https://docs.crawl4ai.com/#documentation-structure)\n",
      "  * [How You Can Support](https://docs.crawl4ai.com/#how-you-can-support)\n",
      "  * [Quick Links](https://docs.crawl4ai.com/#quick-links)\n",
      "\n",
      "\n",
      "> Feedback \n",
      "##### Search\n",
      "xClose\n",
      "Type to start searching\n",
      "[ Ask AI ](https://docs.crawl4ai.com/core/ask-ai/ \"Ask Crawl4AI Assistant\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from crawl4ai import AsyncWebCrawler\n",
    "\n",
    "async def main():\n",
    "    #Âª∫Á´ã‰∏ÄÂÄãAsyncWebCrawlerÁöÑÂØ¶È´î\n",
    "    async with AsyncWebCrawler() as crawler:\n",
    "        #Run the crawler on a URL\n",
    "        result = await crawler.arun(url='https://crawl4ai.com')\n",
    "\n",
    "        #ÂàóÂç∞ÂèñÂá∫ÁöÑÁµêÊûú\n",
    "        print(result.markdown)\n",
    "\n",
    "#Âü∑Ë°åasyncio.run()\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_crawler",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
